% template!!
\documentclass[sigconf,anonymous]{acmart}

\usepackage{amsmath}
\usepackage[linesnumbered,boxed]{algorithm2e}
\usepackage{subfigure}
\usepackage{graphicx}
\usepackage{color}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{tikz}
\usetikzlibrary{bayesnet}

\newenvironment{shrinkeq}[1]
{ \bgroup
  \addtolength\abovedisplayshortskip{#1}
  \addtolength\abovedisplayskip{#1}
  \addtolength\belowdisplayshortskip{#1}
  \addtolength\belowdisplayskip{#1}}
{\egroup\ignorespacesafterend}



\setcopyright{none}

\begin{document}

%???MNAR title?
\title{Drug Target Interaction Prediction with Missing not at Random Labels}

%\author{Chen Lin, Sheng Ni, Xiangxiang Zeng}
\begin{abstract}
We introduce a novel probabilistic model, \textbf{F}actorization with \textbf{M}issing \textbf{N}ot at \textbf{R}andom \textbf{L}abels (FMNRL), for \textbf{D}rug-\textbf{T}arget \textbf{I}nteraction (DTI) prediction. Unlike previous studies which label unknown DTIs as negative samples, we treat the unnown DTIs as missing not at random responses. FMNRL assumes the labels are probabilistically generated from feature vectors of both drugs and targets, and a hidden matrix mapping from the drug features to target features. By associating the possibility of a missing response to the possibility of a negative label, FMNRL can learn the hidden feature space mapping better and thus provide more accurate DTI predictions. Experimental results show that FMNRL outperforms state-of-the-art methods. 

\end{abstract}


\keywords{Missing Not At Random, Drug Target Interaction Prediction, Probabilistic Factor Models}

\maketitle
\section{Introduction}\label{sec:introduction}
%Background: DTI
\textbf{D}rug-\textbf{T}arget \textbf{I}nteraction (DTI) is fundamental to drug discovery and design. As biochemical experimental methods for DTI identification are extremely costly and time-consuming, computational DTI prediction methods have received a growing popularity in literature. The mojority of existing computational methods treat DTI prediction as a binary classification task, where known DTIs are labeled as positive and unknown DTIs are labeled as negative~\cite{Ding2013Similarity}. To address the imbalanced problem arised from the binary classification scheme, many research works attempt to extract a subset of reliable negative samples, e.g. by random sampling~\cite{Luo2017Network} or by \textbf{U}nlabel \textbf{L}earning (PU Learning)~\cite{Peng2017Screening}. 

%MNAR intuition
Instead of labeling the unknown DTIs as negative, we argue that it is more natural to consider the unknown DTIs, i.e. DTIS that are neither identified in vivo to be positive nor experimentally validated to be negative (non-interacting drug-target pairs), as missing responses (i.e. the labels are missing). Our assumption in this work is that labels are not missing at random. This is an intuitive and reasonable assumption because researchers will use their domain expertise to filter DTIs with a high possiblity to be positive and priorize validations for these DTIs in vivo. For example, if researchers prefer to validate drugs with certain pharmacokinetic interactions, i.e. one drug affects the in vivo absorption, distribution, metabolism, or excretion of the target, then the unknown DTIs are not missing at random because drugs without pharmacokinetic interactions with the target are less likely to be positive and hence more likely to be missing.   

\subsection{Contribution}
%present work 
Our chief contribution in this work is a novel \textbf{F}actorization with \textbf{M}issing \textbf{N}ot at \textbf{R}andom \textbf{L}abels model (FMNRL). To the best of our knowledge, this is the first time missing not at random theory is applied in DTI identification. The inputs of FMNRL are feature vectors of drugs and targets which are leant and integrated from heterogenous data sources, the partially observed labels (i.e. positive or negative), and the fully observed reponses (i.e. given or missing). The FMNRL model mimics the probabilitic procedures to generate the labels from feature vectors and the responses from labels. Specifically, the labels are related to feature vectors of both drugs and targets, and a hidden matrix mapping from the drug features to target features. The possibility of giving a response is associated to the possibility of a positive label.  

We conduct experiments on a large-scale DPI database. Our model achieves significantly better AUPR result and comparable AUROC result to the best of related works~\cite{Luo2017Network}. In the biomedical field, AUROC is considered to be a more robust and better assessment than AUROC~\cite{Luo2017Network}. Thus our improvment in AUPR is promising.
\subsection{Related Work}
%distinguision 
One component of our work (i.e labels are generated by feature vectors learnt and fused from heterogenous information networks) is inspired by a recent work DTINet~\cite{Luo2017Network}. However, there are three key differences between our work and DTINet. (1) DTINet is based on deteministic matrix factorization, our work is based on probabilistic factor models. For example, the hidden feature space mapping matrix, labels, and responses are all random variables. This setting enables the FMNRL model to regulate the parameters (i.e. hidden feature space mapping matrix) by introducing approapriate priors and improves performance on sparse data set. (2) DTINet is based on randomly missing responses, i.e. it samples uniformly a set of unknown DTIs as negative sample, while FMNRL is based on missing not at random theories. Statistical theory in~\cite{Little1987Statistical} shows that applying a model based on missing at random assumptions can lead to biased parameter estimation on data sets with missing not at random entries (3) DTINet adopts only a subset of unknown DTIs to preserve a balanced number of positive and negative samples, while our model uses all information in the data set.

We also want to distinguish our work with another line of research. Usually only positive DTIs are deposited in known databases. Due to the lack of negative samples, recently \textbf{P}ositive \textbf{U}nlabel \textbf{L}earning (PU Learning) is empolyed in DTI identification, e.g. to facilitate negative sample extraction~\cite{Peng2017Screening}. PU learning does not explicitly associate the status of an instance (i.e. being positive or unlabel) with the value of its hidden label. We also want to mention here that, although we experiment with datasets where only positive DTIs are deposited, FMNRL is extendable without difficulty to databases where positive and negative DTIs are available. Thus our model is applicable in more scenarios.    


%structure 
%This paper is structured as follows. 





\section{The Proposed Method}\label{sec:method}
\subsection{Preliminaries}\label{sec:input}
Given a set of DTI labels $P=\{p\}$, where $p\in \{0,1\}$. responses  $P=\{p\}$, where $p\in \{0,1\}$
\subsection{Model}\label{sec:model}


\begin{figure}
  \centering
  \tikz{ %
%hyper parameters
  %latent nodes
    \node[const] (x) {$X$} ; %
    \node[const, right =of x] (y) {$Y$};
     \node[const, right =of y] (sigma) {$\sigma^2$};
  	\node[latent, below = of sigma] (z) {$Z$};       
       %per interaction
    \node[obs, below=2 of z](p){$p$};
      \node[obs, below= of p] (r){$r$}; 
	\node[latent, right = 2 of r] (beta){$\beta$};
	\node[const,right = of beta](eta) {$\eta$};
    \edge{x}{p};
    \edge{sigma}{z};
    \edge{y}{p};
    \edge{z}{p};
    \edge{p}{r};
	\edge{beta}{r};
	\edge{eta}{beta};
     \plate[inner sep=0.2cm, xshift=-0.12cm, yshift=0.12 cm] {plate} {(p) (r)} {N}; 
	 \plate[inner sep=0.2cm, xshift=-0.12cm, yshift=0.12 cm] {plate2} {(beta)} {2}; 

 }
\caption{Graphical Representation of the FMNRL model}
\end{figure}

\begin{eqnarray}
z\sim \mathcal{N}((0,\sigma^2)\\
p(p=1)=\frac{1}{1+\exp{(xzy)}}\\
\beta \sim Beta(\eta)\\
r\sim Bern (\beta_p)
\end{eqnarray}

\subsection{Inference}\label{sec:inference}


\section{Experiment}\label{sec:experiment}
\subsection{Experimental Setup}

\subsection{Results and Analysis}



\section{Conclusion}\label{sec:conclusion}


\begin{thebibliography}{10}
\bibitem{Ding2013Similarity}
Ding, H., Takigawa, I., Mamitsuka, H., and Zhu, S. 
\newblock Similarity-based machine learning methods for predicting drugâ€“target interactions: a brief review. \newblock In {\em Briefings in bioinformatics}, 15(5), 734-747.
\bibitem{Peng2017Screening}
Peng L, Zhu W, Liao B, et al. 
\newblock Screening drug-target interactions with positive-unlabeled learning. 
\newblock In {\em Scientific Reports}, 2017, 7(1): 8087.

\bibitem{Little1987Statistical}
R. J. A. Little and D. B. Rubin. 
\newblock Statistical Analysis with Missing Data, 1987.

\bibitem{Luo2017Network}
Luo Y, Zhao X, Zhou J, et al. 
\newblock A network integration approach for drug-target interaction prediction and computational drug repositioning from heterogeneous information. 
\newblock In {\em Nature Communications}, 2017, 8(1).

\end{thebibliography}
%\balancecolumns
\end{document}
